#!/usr/bin/env python3
"""
An√°lise detalhada dos gaps e ajustes na taxonomia dos 96 h√°drons
"""

import json
from pathlib import Path
from typing import Dict, List, Tuple, Set
from spectrometer_hadrons_engine import HADRON_CATALOG

class GapAnalyzer:
    """Analisa os gaps e prop√µe ajustes na taxonomia"""

    def __init__(self):
        self.results_path = Path("batch_analysis_results.json")
        self.gap_analysis = self._load_and_analyze()

    def _load_and_analyze(self) -> Dict:
        """Carrega resultados e analisa gaps"""
        with open(self.results_path, 'r') as f:
            results = json.load(f)

        stats = results["global_statistics"]
        missing = set(stats["missing_hadrons"])

        # Categoriza os missing
        categorized_gaps = self._categorize_missing_hadrons(missing)

        # Identifica padr√µes nos gaps
        gap_patterns = self._identify_gap_patterns(results)

        # Prop√µe ajustes
        adjustments = self._propose_adjustments(categorized_gaps, gap_patterns)

        return {
            "missing_hadrons": list(missing),
            "missing_count": len(missing),
            "coverage_percentage": stats["hadron_coverage"],
            "categorized_gaps": categorized_gaps,
            "gap_patterns": gap_patterns,
            "proposed_adjustments": adjustments,
            "priority_actions": self._determine_priority_actions(categorized_gaps, gap_patterns)
        }

    def _categorize_missing_hadrons(self, missing: Set[str]) -> Dict[str, Dict]:
        """Categoriza os h√°drons n√£o encontrados"""
        categories = {
            "syntax_level": {
                "description": "Elementos de baixo n√≠vel (sintaxe)",
                "hadrons": [],
                "impact": "low",
                "reason": "Provavelmente existem mas n√£o foram detectados pelas heur√≠sticas"
            },
            "rare_patterns": {
                "description": "Padr√µes raros ou espec√≠ficos de dom√≠nio",
                "hadrons": [],
                "impact": "medium",
                "reason": "Aparecem apenas em contextos espec√≠ficos"
            },
            "framework_specific": {
                "description": "Espec√≠ficos de frameworks ou tecnologias",
                "hadrons": [],
                "impact": "medium",
                "reason": "Dependem de frameworks espec√≠ficos"
            },
            "obselete_or_theoretical": {
                "description": "Te√≥ricos ou obsoletos",
                "hadrons": [],
                "impact": "low",
                "reason": "Podem n√£o ser mais relevantes"
            },
            "detection_issue": {
                "description": "Problema de detec√ß√£o",
                "hadrons": [],
                "impact": "high",
                "reason": "Provavelmente existem mas o parser n√£o encontrou"
            }
        }

        # Classifica cada hadron missing
        for hadron in missing:
            if hadron in ["BitFlag", "BitMask", "ParityBit", "SignBit",
                         "ByteArray", "MagicBytes", "PaddingBytes"]:
                categories["syntax_level"]["hadrons"].append(hadron)

            elif hadron in ["WebSocketHandler", "QueueWorker", "BackgroundThread",
                           "Actor", "Fiber", "WebWorker", "ServiceWorker"]:
                categories["rare_patterns"]["hadrons"].append(hadron)

            elif hadron in ["GraphQLResolver", "KubernetesJob", "CronJob",
                           "ContainerEntry", "LambdaEntry"]:
                categories["framework_specific"]["hadrons"].append(hadron)

            elif hadron in ["PanicRecover", "ChaosMonkey"]:
                categories["obselete_or_theoretical"]["hadrons"].append(hadron)

            else:
                categories["detection_issue"]["hadrons"].append(hadron)

        return categories

    def _identify_gap_patterns(self, results: Dict) -> Dict:
        """Identifica padr√µes nos gaps por categoria de reposit√≥rio"""
        patterns = {
            "common_across_all": [],
            "category_specific": {},
            "language_specific": {}
        }

        repo_results = results["repository_results"]

        # H√°drons que faltam em m√∫ltiplos reposit√≥rios
        missing_counts = {}
        category_missing = {}

        for result in repo_results:
            category = result["category"]
            missing = result["statistics"]["missing_hadrons"]

            if category not in category_missing:
                category_missing[category] = {}

            for hadron in missing:
                missing_counts[hadron] = missing_counts.get(hadron, 0) + 1
                category_missing[category][hadron] = category_missing[category].get(hadron, 0) + 1

        # H√°drons que faltam em 50%+ dos reposit√≥rios
        threshold = len(repo_results) * 0.5
        patterns["common_across_all"] = [
            hadron for hadron, count in missing_counts.items()
            if count >= threshold
        ]

        # Por categoria
        for category, missing_map in category_missing.items():
            category_threshold = sum(1 for r in repo_results if r["category"] == category) * 0.6
            patterns["category_specific"][category] = [
                hadron for hadron, count in missing_map.items()
                if count >= category_threshold
            ]

        return patterns

    def _propose_adjustments(self, categorized: Dict, patterns: Dict) -> List[Dict]:
        """Prop√µe ajustes espec√≠ficos na taxonomia"""
        adjustments = []

        # 1. Fundir h√°drons muito similares
        adjustments.append({
            "type": "merge",
            "description": "Fundir h√°drons de n√≠vel sint√°tico",
            "reason": "Elementos como BitFlag, BitMask, ParityBit s√£o muito espec√≠ficos",
            "proposal": {
                "new_hadron": "BitOperation",
                "merge_from": ["BitFlag", "BitMask", "ParityBit", "SignBit"],
                "form": "tetrahedron+binary_ops"
            }
        })

        adjustments.append({
            "type": "merge",
            "description": "Consolidar handlers de sistema",
            "reason": "WebSocketHandler, QueueWorker, etc s√£o espec√≠ficos demais",
            "proposal": {
                "new_hadron": "SystemEventHandler",
                "merge_from": ["WebSocketHandler", "QueueWorker", "MessageConsumer"],
                "form": "icosahedron+system"
            }
        })

        # 2. Adicionar h√°drons mais gen√©ricos
        adjustments.append({
            "type": "add_generic",
            "description": "Adicionar h√°drons gen√©ricos para cobrir gaps",
            "reason": "Faltam padr√µes b√°sicos comuns",
            "proposal": [
                {
                    "name": "FieldAccess",
                    "continent": "DATA_FOUNDATIONS",
                    "fundamental": "EXPRESSIONS",
                    "form": "cone+field",
                    "description": "Acesso a campos/atributos"
                },
                {
                    "name": "ImportStatement",
                    "continent": "ORGANIZATION",
                    "fundamental": "MODULES",
                    "form": "dodecahedron+import",
                    "description": "Declara√ß√µes de import/export"
                },
                {
                    "name": "ErrorHandling",
                    "continent": "LOGIC_FLOW",
                    "fundamental": "CONTROL_STRUCTURES",
                    "form": "torus+error",
                    "description": "Qualquer forma de tratamento de erro"
                }
            ]
        })

        # 3. Ajustar heur√≠sticas de detec√ß√£o
        adjustments.append({
            "type": "improve_detection",
            "description": "Melhorar detec√ß√£o de padr√µes existentes",
            "reason": "Muitos h√°drons existem mas n√£o foram detectados",
            "proposal": [
                {
                    "hadron": "TryCatch",
                    "improvement": "Detectar try/except, try/catch em qualquer linguagem",
                    "patterns": [r"try\s*{", r"except\s+", r"catch\s*\("]
                },
                {
                    "hadron": "InstanceField",
                    "improvement": "Detectar self.attr, this.attr",
                    "patterns": [r"self\.\w+", r"this\.\w+"]
                },
                {
                    "hadron": "StaticField",
                    "improvement": "Detectar acesso a classe/static",
                    "patterns": [r"ClassName\.\w+", r"static\s+\w+"]
                }
            ]
        })

        # 4. Remover h√°drons obsoletos
        adjustments.append({
            "type": "remove",
            "description": "Remover h√°drons te√≥ricos ou obsoletos",
            "reason": "N√£o aparecem no c√≥digo real",
            "proposal": {
                "remove": ["PanicRecover", "ChaosMonkey", "SelfHealingProbe"],
                "justification": "S√£o conceitos te√≥ricos, n√£o padr√µes de c√≥digo"
            }
        })

        return adjustments

    def _determine_priority_actions(self, categorized: Dict, patterns: Dict) -> List[Dict]:
        """Determina a√ß√µes priorit√°rias baseado nos gaps"""
        actions = []

        # A√ß√µes de alta prioridade
        if len(categorized["detection_issue"]["hadrons"]) > 10:
            actions.append({
                "priority": "HIGH",
                "action": "Fix detection heuristics",
                "target": categorized["detection_issue"]["hadrons"],
                "impact": "Immediato na cobertura",
                "effort": "Baixo - s√≥ ajustar regex/patterns"
            })

        if patterns["common_across_all"]:
            actions.append({
                "priority": "HIGH",
                "action": "Address common gaps",
                "target": patterns["common_across_all"],
                "impact": "Alto - afeta todos os reposit√≥rios",
                "effort": "M√©dio - precisa an√°lise profunda"
            })

        # A√ß√µes de m√©dia prioridade
        actions.append({
            "priority": "MEDIUM",
            "action": "Merge similar hadrons",
            "target": ["BitFlag", "BitMask", "WebSocketHandler", "QueueWorker"],
            "impact": "Reduz complexidade sem perder informa√ß√£o",
            "effort": "Baixo"
        })

        # A√ß√µes de baixa prioridade
        actions.append({
            "priority": "LOW",
            "action": "Remove obsolete hadrons",
            "target": categorized["obselete_or_theoretical"]["hadrons"],
            "impact": "Limpeza da taxonomia",
            "effort": "M√≠nimo"
        })

        return actions

    def generate_adjusted_taxonomy(self) -> Dict:
        """Gera taxonomia ajustada com as mudan√ßas propostas"""
        # Come√ßa com o cat√°logo original
        adjusted_catalog = HADRON_CATALOG.copy()

        # Aplica ajustes propostos
        for adj in self.gap_analysis["proposed_adjustments"]:
            if adj["type"] == "merge":
                # Remove os originais e adiciona o novo
                for hadron in adj["proposal"]["merge_from"]:
                    if hadron in adjusted_catalog:
                        del adjusted_catalog[hadron]

                # Adiciona o novo h√°dron
                new_name = adj["proposal"]["new_hadron"]
                # Precisa definir continent/fundamental baseado nos mesclados
                if adjusted_catalog:
                    # Usa o primeiro como refer√™ncia
                    first = adj["proposal"]["merge_from"][0]
                    if first in HADRON_CATALOG:
                        adjusted_catalog[new_name] = {
                            "continent": HADRON_CATALOG[first]["continent"].value,
                            "fundamental": HADRON_CATALOG[first]["fundamental"].value,
                            "form": adj["proposal"]["form"]
                        }

            elif adj["type"] == "remove":
                for hadron in adj["proposal"]["remove"]:
                    if hadron in adjusted_catalog:
                        del adjusted_catalog[hadron]

        # Adiciona novos gen√©ricos
        for adj in self.gap_analysis["proposed_adjustments"]:
            if adj["type"] == "add_generic":
                for new_hadron in adj["proposal"]:
                    adjusted_catalog[new_hadron["name"]] = {
                        "continent": new_hadron["continent"],
                        "fundamental": new_hadron["fundamental"],
                        "form": new_hadron["form"]
                    }

        return {
            "original_count": len(HADRON_CATALOG),
            "adjusted_count": len(adjusted_catalog),
            "reduction": len(HADRON_CATALOG) - len(adjusted_catalog),
            "catalog": adjusted_catalog
        }

    def save_analysis(self, output_path: Path):
        """Salva an√°lise completa dos gaps"""
        analysis = {
            "metadata": {
                "missing_hadrons": self.gap_analysis["missing_count"],
                "coverage": self.gap_analysis["coverage_percentage"],
                "timestamp": "2025-12-03"
            },
            "gap_analysis": self.gap_analysis,
            "adjusted_taxonomy": self.generate_adjusted_taxonomy(),
            "next_steps": [
                "1. Implement detection improvements for top 10 missing hadrons",
                "2. Test adjusted taxonomy with new sample",
                "3. Validate LLM enrichment for edge cases",
                "4. Finalize taxonomy v4.1"
            ]
        }

        with open(output_path, 'w') as f:
            json.dump(analysis, f, indent=2)

        # Gera resumo executivo
        summary_path = output_path.with_suffix('.md')
        self._generate_summary(analysis, summary_path)

    def _generate_summary(self, analysis: Dict, output_path: Path):
        """Gera resumo em Markdown"""
        gap = analysis["gap_analysis"]
        taxonomy = analysis["adjusted_taxonomy"]

        summary = f"""# GAP ANALYSIS & TAXONOMY ADJUSTMENTS

## üéØ Key Findings

- **Missing Hadrons**: {gap['missing_count']}/96 ({gap['coverage_percentage']}% coverage)
- **Main Issue**: Detection problems, not taxonomy problems
- **Recommendation**: Adjust taxonomy to ~85 hadrons with better detection

## üìä Gap Categories

### Critical Issues (Detection)
- {len(gap['categorized_gaps']['detection_issue']['hadrons'])} hadrons n√£o detectados corretamente
- Impacto: Alto - afeta diretamente a cobertura

### Low Impact (Syntax Level)
- {len(gap['categorized_gaps']['syntax_level']['hadrons'])} elementos de baixo n√≠vel
- Podem ser agrupados em hadrons mais gen√©ricos

## üîß Proposed Adjustments

### 1. Merge Similar Hadrons
- **BitFlag, BitMask, ParityBit, SignBit** ‚Üí **BitOperation**
- **WebSocketHandler, QueueWorker, MessageConsumer** ‚Üí **SystemEventHandler**

### 2. Add Generic Patterns
- **FieldAccess** - Padr√£o muito comum n√£o detectado
- **ImportStatement** - Essencial para an√°lise de depend√™ncias
- **ErrorHandling** - Gen√©rico para try/catch/except

### 3. Improve Detection
- Add regex patterns for TryCatch, InstanceField, StaticField
- Multi-language support (Java, Go, Rust, TypeScript)

### 4. Remove Obsolete
- PanicRecover, ChaosMonkey, SelfHealingProbe

## üìà Expected Impact

- **Before**: 96 hadrons, 52.3% coverage
- **After**: ~85 hadrons, estimated 75%+ coverage
- **Benefit**: Mais focado, melhor detec√ß√£o, mais √∫til

## ‚úÖ Priority Actions

1. **IMMEDIATE**: Fix detection heuristics for top 10 missing
2. **SHORT-TERM**: Implement adjusted taxonomy
3. **MEDIUM-TERM**: Add LLM enrichment for edge cases
4. **LONG-TERM**: Expand validation dataset

---
Analysis completed: 2025-12-03
"""

        with open(output_path, 'w') as f:
            f.write(summary)

# ========================
# EXECU√á√ÉO PRINCIPAL
# ========================

if __name__ == "__main__":
    analyzer = GapAnalyzer()

    # Salva an√°lise completa
    output_file = Path("gap_analysis_adjustments.json")
    analyzer.save_analysis(output_file)

    print("\n" + "="*60)
    print("GAP ANALYSIS COMPLETE")
    print("="*60)
    print(f"Arquivo de an√°lise: {output_file}")
    print(f"Taxonomia ajustada para {analyzer.generate_adjusted_taxonomy()['adjusted_count']} h√°drons")
    print(f"Redu√ß√£o de {analyzer.generate_adjusted_taxonomy()['reduction']} h√°drons")
    print("\nPr√≥ximos passos:")
    for step in analyzer.gap_analysis["priority_actions"][:3]:
        print(f"  - [{step['priority']}] {step['action']}")