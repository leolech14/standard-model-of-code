{
  "_meta": {
    "saved_at": "2026-01-26T02:28:54.020575",
    "source": "gemini",
    "model": "gemini-3-pro-preview",
    "query": "Critical architectural decision: I want to AUTO-INJECT context into Claude's workflow WITHOUT requiring tool calls. Options: 1) Pre-hook injection (user-prompt-submit-hook), 2) MCP resource auto-loading, 3) System prompt dynamic refresh, 4) CLAUDE.md @imports. Which is best for: a terminal-based intel feed that provides meters, available cards, session state, alerts BEFORE the LLM starts thinking. The goal is zero agentic overhead - context is ALREADY THERE like a pilot's instrument panel. What are the tradeoffs? What's the recommended pattern?",
    "query_length": 550,
    "checksum": "sha256:6dc2a6ae176cbe1be5898dc650a2960fe9c558b8e1f3528d0c54a566faf2cf24"
  },
  "response": {
    "content": "Based on the `PROJECT_elements` architecture‚Äîspecifically the **ACI (Adaptive Context Intelligence)** system and the **Observer Realm (.agent/)**‚Äîhere is the architectural recommendation.\n\n### Executive Decision: Option 1 (Pre-hook Injection via CLI Wrapper)\n\nFor a \"pilot's instrument panel\" (zero latency, zero tool use, always visible), **Pre-hook Injection via the `./pe` CLI wrapper** is the only viable architecture.\n\n**Why:**\n1.  **Zero-Shot Awareness:** The LLM sees the state *before* it generates the first token.\n2.  **No Tool Loop:** Options 2 (MCP) often require the model to *decide* to look at a resource, or rely on client-specific auto-attach implementations that are flaky.\n3.  **Dynamic vs. Static:** `CLAUDE.md` is for *policy* (static). The Instrument Panel is for *state* (dynamic).\n4.  **Codome/Contextome Alignment:** This effectively creates a transient \"Session Contextome\" that exists only for the duration of the turn.\n\n---\n\n### The Tradeoff Analysis\n\n| Pattern | Latency | Agency Cost | Best For | Verdict |\n| :--- | :--- | :--- | :--- | :--- |\n| **1. Pre-hook Injection** | **Zero** | **Zero** | **State, Meters, Alerts** | **üèÜ WINNER** |\n| **2. MCP Auto-load** | Low | Low/Med | Large Ref Docs, Logs | Good for \"Library\", not \"HUD\" |\n| **3. System Prompt** | Zero | High (Reset) | Personality, Core Laws | Too rigid for changing state |\n| **4. CLAUDE.md** | Zero | None | Static Policy, Formatting | Impossible for real-time state |\n\n### The \"Context HUD\" Pattern\n\nYou should implement a **Context Compositor** inside your `./pe` entry point. When a user runs `./pe ask \"fix the bug\"`, the system does not send \"fix the bug\" to the LLM. It sends:\n\n```xml\n<instrument_panel>\n  <meters>\n    <focus>5/10</focus>\n    <rigor>8/10</rigor>\n    <drift>CRITICAL (Doc/Code mismatch)</drift>\n  </meters>\n  <session>\n    <active_task>TASK-124: Refactor Auth</active_task>\n    <sprint_status>EXECUTING</sprint_status>\n  </session>\n  <deck>\n    <available_cards>\n      <card id=\"CARD-ANA-001\">Deep Analysis</card>\n      <card id=\"CARD-REF-002\">Safe Refactor</card>\n    </available_cards>\n  </deck>\n  <alerts>\n    <alert level=\"high\">AM002 Violation detected in src/core/pipeline.py</alert>\n  </alerts>\n</instrument_panel>\n\n<user_query>\nfix the bug\n</user_query>\n```\n\n### Implementation Plan\n\nThis fits directly into your **ACI (Adaptive Context Intelligence)** system defined in `context-management/config/aci_config.yaml`.\n\n#### 1. Define the HUD Source\nCreate a lightweight aggregator in `context-management/tools/ai/aci/hud_builder.py` that pulls strictly from `.agent/` (Observer realm).\n\n*   **Input:** `.agent/state/meters.yaml`, `.agent/registry/active/*.yaml`, `.agent/state/play_log.yaml`\n*   **Output:** Compact XML string.\n\n#### 2. Modify the CLI Entry Point (`./pe`)\nUpdate your `./pe` wrapper (Layer 1 abstraction) to invoke the HUD builder before constructing the payload.\n\n```python\n# Pseudo-code for ./pe or context-management/tools/ai/analyze.py\n\ndef construct_final_prompt(user_query):\n    hud = aci.hud_builder.build(\n        include_meters=True,\n        include_deck=True, \n        verbosity=\"compact\" # Keep token cost low\n    )\n    return f\"{hud}\\n\\nUser Query: {user_query}\"\n```\n\n#### 3. Update `aci_config.yaml`\nAdd a section to control HUD density to manage token costs.\n\n```yaml\n# context-management/config/aci_config.yaml\n\ninstrument_panel:\n  enabled: true\n  format: \"xml\"\n  elements:\n    meters: true\n    active_task: true\n    deck_hand: true    # Only show playable cards\n    full_registry: false # Too large, force tool use\n  injection_strategy: \"prepend_user_message\"\n```\n\n### Why this fits PROJECT_elements\n\n1.  **Observability (Axiom G):** The HUD satisfies the \"Complete Observability\" axiom in `CODESPACE_ALGEBRA.md`. It forces the \"Secondness\" (actual brute facts of the session) into the \"Thirdness\" (interpretation) of the LLM.\n2.  **Symmetry:** It prevents the **AMNESIAC** state defined in your glossary (Code exists, Intent recorded, but Human/Agent has no structural memory). The HUD bridges the memory gap instantly.\n3.  **Cost:** It uses the **Instant Tier** (cached truths) logic from ACI to build the string, incurring $0 computation cost and minimal token cost.\n\n### Recommendation\n\n**Do not use MCP for the Instrument Panel.** Use MCP for the *Library* (looking up docs/code). Use **Pre-hook Injection** for the *Cockpit* (meters/state).\n\n**Action Item:** Create `context-management/tools/ai/aci/hud_builder.py` and wire it into the `analyze.py` prompt construction flow immediately.",
    "mode": "standard"
  }
}