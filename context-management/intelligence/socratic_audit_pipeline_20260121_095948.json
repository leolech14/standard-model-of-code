{
  "timestamp": "20260121_095948",
  "domain": "pipeline",
  "execution_id": "pipeline-20260121_095948",
  "generation": 1,
  "parent_execution_id": null,
  "analysis_type": "primary",
  "source": {
    "type": "repository",
    "location": "/Users/lech/PROJECTS_all/PROJECT_elements"
  },
  "results": [
    {
      "hypothesis": {
        "concept": "Stage",
        "claim": "Hypothesis: The concept 'Stage' is implemented according to strict invariants.",
        "description": "A processing unit in the analysis pipeline.",
        "invariants": [
          "Must inherit from a base Stage class (e.g., BaseStage)",
          "Must implement an 'execute' or 'run' method",
          "Should be stateless (no instance variables modified during run)",
          "Must return a standard result format (ProcessingResult/AnalysisResult)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_stage.py",
            "pattern": "class *Stage"
          },
          {
            "file": "standard-model-of-code/src/core/full_analysis.py",
            "pattern": "class FullAnalysisPipeline"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/full_analysis.py"
        ],
        "analysis": "### Findings\n- **Entity**: `run_full_analysis` and its internal processing steps (e.g., `compute_markov_matrix`, `detect_knots`, `compute_data_flow`).\n- **Status**: Non-Compliant\n- **Evidence**: The analysis pipeline is implemented as a single, large orchestrator function, `run_full_analysis`. The conceptual \"stages\" are sequential blocks of code within this function that call other standalone helper functions.\n```python\ndef run_full_analysis(target_path: str, output_dir: str = None, options: Dict[str, Any] = None) -> Dict:\n    ...\n    # Stage 5: Markov Matrix\n    print(\"\\n\ud83d\udcca Stage 5: Markov Transition Matrix...\")\n    with StageTimer(perf_manager, \"Stage 5: Markov Transition Matrix\") as timer:\n        markov = compute_markov_matrix(nodes, edges)\n        ...\n\ndef compute_markov_matrix(nodes: List[Dict], edges: List[Dict]) -> Dict:\n    ...\n```\n- **Deviation**: The implementation is procedural rather than the object-oriented structure described in the semantic definition.\n    - **Inheritance**: The processing units are standalone functions (e.g., `compute_markov_matrix`), not classes that inherit from a `BaseStage`.\n    - **Method Name**: They are functions called directly, not objects with a standardized `execute` or `run` method.\n    - **Return Type**: The functions return standard Python dictionaries (`Dict`), not a formalized `ProcessingResult` or `AnalysisResult` object.\n    - **Statelessness**: The pattern is mostly stateless. However, some functions like `compute_markov_matrix` violate this by modifying their input arguments (a side-effect): `edge['markov_weight'] = transitions[source][target]`.",
        "guardrails": {
          "compliant": false,
          "violations": [
            {
              "law_id": "AM004",
              "severity": "HIGH",
              "reasoning": "The function `classify_disconnection` is a large, non-trivial function (over 100 lines) with detailed logic and comments, but it is never called within the main `run_full_analysis` execution pipeline. This represents significant dead code that increases maintenance overhead and creates confusion about the system's actual capabilities, as its well-documented purpose of providing a 'Rich classification of why nodes appear disconnected' is not being utilized."
            },
            {
              "law_id": "AM002",
              "severity": "MEDIUM",
              "reasoning": "The function `_generate_ai_insights` shells out to a completely separate python script (`analyze.py`) to perform its task. While this can be a valid decoupling strategy, it introduces significant architectural fragility. The script's location is determined by a brittle relative path traversal (`Path(__file__).parent.parent.parent.parent`), and communication relies on temporary files and parsing stdout. This violates the 'Stage' role's principle of cohesive orchestration by outsourcing a core step to an external process in a non-robust way, creating a hidden, high-friction dependency instead of a direct, type-safe internal call."
            },
            {
              "law_id": "AM001",
              "severity": "LOW",
              "reasoning": "The private helper functions `_open_file` and `_manual_open_command` implement common cross-platform file opening logic. This is a form of Context Myopia, as such general utility functionality is likely needed elsewhere and should reside in a shared, project-wide utility module rather than being locally reimplemented within this specific analysis stage."
            }
          ],
          "critique_summary": "The code fails its audit due to containing a large block of orphaned logic and employing a brittle external process call, despite being a generally well-structured orchestrator."
        }
      }
    },
    {
      "hypothesis": {
        "concept": "Extractor",
        "claim": "Hypothesis: The concept 'Extractor' is implemented according to strict invariants.",
        "description": "Component responsible for raw data ingestion.",
        "invariants": [
          "Must operate on raw file content or AST",
          "Must not perform complex semantic reasoning (role of Classifier)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_extractor*.py",
            "pattern": "class *Extractor"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/edge_extractor.py",
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/smart_extractor.py"
        ],
        "analysis": "### Findings\n- **Entity**: `EdgeExtractionStrategy` (and its regex-based subclasses like `PythonEdgeStrategy`, `JavascriptEdgeStrategy`)\n- **Status**: Compliant\n- **Evidence**: These classes operate on the `body_source` of a particle, which is raw file content. They use regular expressions to find syntactic patterns. For example, `PythonEdgeStrategy` uses `re.findall(r'(?:self\\.)?(\\w+)\\s*\\(', body)` to find potential function calls. This is a pure extraction of call-like syntax without deeper analysis.\n- **Deviation**: N/A\n\n---\n- **Entity**: `TreeSitterEdgeStrategy` (and compliant subclasses like `PythonTreeSitterStrategy`)\n- **Status**: Compliant\n- **Evidence**: This strategy and its compliant subclasses operate by parsing the raw `body_source` into an AST (`tree = self.parser.parse(source_bytes)`) and traversing it to find syntactic nodes like `call` expressions. This adheres to the invariant \"Must operate on raw file content or AST\" and does not perform semantic reasoning beyond identifying a syntactic construct.\n- **Deviation**: N/A\n\n---\n- **Entity**: `_extract_exposure_edges_from_body`\n- **Status**: Compliant\n- **Evidence**: This function operates directly on a raw string of code (`body`) using regular expressions to find syntactic patterns related to module exports (e.g., `re.findall(r'export\\s+class\\s+(\\w+)', body)`). It extracts information without interpreting the code's meaning.\n- **Deviation**: N/A\n\n---\n- **Entity**: `JSModuleResolver`\n- **Status**: Non-Compliant\n- **Evidence**: The class's explicit purpose is to perform semantic reasoning. Its docstring states it \"Resolves JavaScript module references across files\" by tracking aliases and exports. The `resolve_member_call` method uses this tracked information to determine the true source of a function call.\n- **Deviation**: This component's role is resolution, not raw data ingestion. It builds a semantic model of the module system (`self.window_exports`, `self.import_aliases`) and uses it to connect different parts of the code. This violates the invariant \"Must not perform complex semantic reasoning\", which is defined as the role of the `Classifier`.\n\n---\n- **Entity**: `JavaScriptTreeSitterStrategy`\n- **Status**: Non-Compliant\n- **Evidence**: This class uses the `JSModuleResolver` to resolve member calls, as seen in its `extract_edges` method: `target = resolver.resolve_member_call(obj_name, method_name, caller_file, particle_by_name)`. It goes beyond simply extracting a call's name and attempts to identify its specific definition.\n- **Deviation**: By using the `JSModuleResolver`, this strategy incorporates complex semantic reasoning (alias and module resolution) to build the call graph. Its goal is not just to extract raw data (a call happened) but to interpret that data (this call goes to *that* specific function), which oversteps the bounds of an Extractor.\n\n---\n- **Entity**: `extract_call_edges`\n- **Status**: Non-Compliant\n- **Evidence**: This orchestrator function is responsible for initializing and populating the `JSModuleResolver`: `reset_js_module_resolver()`, `resolver = get_js_module_resolver()`, and `resolver.analyze_file(file_path, content)`. It then uses strategies that depend on this resolver.\n- **Deviation**: By setting up and orchestrating the `JSModuleResolver`, this function becomes responsible for performing semantic reasoning. It is not merely ingesting raw import data; it is actively constructing a semantic model for resolving JS modules, which violates the invariant \"Must not perform complex semantic reasoning\".",
        "guardrails": {
          "compliant": false,
          "violations": [
            {
              "law_id": "AM004",
              "severity": "HIGH",
              "reasoning": "The module contains several helper functions that are defined but never called: `_collect_file_node_ids`, `file_node_id`, `file_node_name`, and `module_name_from_path`. These functions appear to be remnants of an incomplete or refactored feature for creating unique file-level nodes in the graph. As private or unexported helpers, their lack of usage within the module makes them orphaned code, increasing maintenance overhead and code clutter."
            },
            {
              "law_id": "AM001",
              "severity": "MEDIUM",
              "reasoning": "The module provides two distinct and parallel implementations for the same task in the same language: a simple, regex-based strategy (e.g., `PythonEdgeStrategy`) and a more robust, high-precision AST-based strategy (e.g., `PythonTreeSitterStrategy`). Maintaining two separate, competing classes for the same core function represents a duplication of logic and a myopic design. A better architecture would unify these into a single strategy that internally selects the best available parsing method (AST-first, with regex as a fallback) rather than requiring an external component to choose between a 'good' and 'better' version."
            },
            {
              "law_id": "AM002",
              "severity": "LOW",
              "reasoning": "The use of a global singleton (`_js_module_resolver`) for state management introduces tight coupling and can complicate testing and concurrent execution. While pragmatic for a single-pass analysis tool, it represents a minor architectural drift from a purely functional 'Extractor' role, which ideally should operate on inputs without relying on or modifying global state. The inclusion of a reset function acknowledges this weakness but does not eliminate the architectural smell."
            }
          ],
          "critique_summary": "The extractor is non-compliant due to significant orphaned code from an abandoned feature and architectural duplication from maintaining parallel regex and AST-based extraction strategies."
        }
      }
    }
  ]
}