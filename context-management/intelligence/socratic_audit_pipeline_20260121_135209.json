{
  "timestamp": "20260121_135209",
  "domain": "pipeline",
  "execution_id": "pipeline-20260121_135209",
  "generation": 1,
  "parent_execution_id": null,
  "analysis_type": "primary",
  "source": {
    "type": "repository",
    "location": "/Users/lech/PROJECTS_all/PROJECT_elements"
  },
  "results": [
    {
      "hypothesis": {
        "concept": "Stage",
        "claim": "Hypothesis: The concept 'Stage' is implemented according to strict invariants.",
        "description": "A processing unit in the analysis pipeline.",
        "invariants": [
          "Must inherit from a base Stage class (e.g., BaseStage)",
          "Must implement an 'execute' or 'run' method",
          "Should be stateless (no instance variables modified during run)",
          "Must return a standard result format (ProcessingResult/AnalysisResult)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_stage.py",
            "pattern": "class *Stage"
          },
          {
            "file": "standard-model-of-code/src/core/full_analysis.py",
            "pattern": "class FullAnalysisPipeline"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/full_analysis.py"
        ],
        "analysis": "### Findings\n- **Entity**: Analysis Pipeline Functions (`analyze`, `enrich_with_standard_model`, `detect_purpose_field`, `detect_execution_flow`, `compute_markov_matrix`, `detect_knots`, `compute_data_flow`, etc.)\n- **Status**: Non-Compliant\n- **Evidence**: The analysis pipeline is orchestrated in the `run_full_analysis` function. It calls a series of imported functions to perform distinct processing steps. For example:\n  ```python\n  # Stage 2: Standard Model enrichment\n  print(\"\\n\ud83e\uddec Stage 2: Standard Model Enrichment...\")\n  with StageTimer(perf_manager, \"Stage 2: Standard Model Enrichment\") as timer:\n      nodes = enrich_with_standard_model(nodes)\n      ...\n  \n  # Stage 3: Purpose Field\n  print(\"\\n\ud83c\udfaf Stage 3: Purpose Field...\")\n  with StageTimer(perf_manager, \"Stage 3: Purpose Field\") as timer:\n      purpose_field = detect_purpose_field(nodes, edges)\n      ...\n  ```\n- **Deviation**: The implementation uses a functional/procedural pattern rather than the object-oriented one described in the invariants.\n    - **Inheritance**: The processing units are standalone functions (e.g., `enrich_with_standard_model`), not classes that inherit from a `BaseStage`.\n    - **Method Signature**: The functions are called by their specific names (`detect_purpose_field`, `compute_markov_matrix`), not a standardized `execute` or `run` method.\n    - **Return Format**: The functions return values of different types and structures. `enrich_with_standard_model` returns a list of nodes, `detect_purpose_field` returns a custom `purpose_field` object, and `compute_markov_matrix` returns a dictionary. There is no standard `ProcessingResult` or `AnalysisResult` format.\n    - **Statelessness**: The implementation does align with the spirit of statelessness. Each function receives data, processes it, and returns a new result without modifying instance variables (as there are no instances). State is explicitly passed from one function to the next.",
        "guardrails": {
          "compliant": false,
          "violations": [
            {
              "law_id": "AM001",
              "severity": "MEDIUM",
              "reasoning": "The `detect_knots` function implements a custom, simplified algorithm for graph cycle detection, a classic problem solved robustly by established libraries (e.g., networkx). The implementation includes comments like `Limit for perf` and `limited`, acknowledging its own shortcomings. This constitutes reinventing a standard utility, which is a form of context myopia that introduces risk of bugs and poor performance compared to using a battle-tested solution."
            },
            {
              "law_id": "AM002",
              "severity": "LOW",
              "reasoning": "The `run_full_analysis` function, located in the `core` layer, contains logic (`_open_file`, `_manual_open_command`) to open the final report in the user's default application. This functionality is a user-interface concern. By embedding it within a core analysis module, the code violates its intended 'Stage' role and creates architectural drift by blending processing logic with presentation-layer actions."
            }
          ],
          "critique_summary": "The code is functionally rich but shows architectural drift by mixing core analysis with UI concerns and context myopia by re-implementing a standard graph algorithm."
        }
      }
    },
    {
      "hypothesis": {
        "concept": "Extractor",
        "claim": "Hypothesis: The concept 'Extractor' is implemented according to strict invariants.",
        "description": "Component responsible for raw data ingestion.",
        "invariants": [
          "Must operate on raw file content or AST",
          "Must not perform complex semantic reasoning (role of Classifier)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_extractor*.py",
            "pattern": "class *Extractor"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/smart_extractor.py",
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/edge_extractor.py"
        ],
        "analysis": "### Findings\n\n- **Entity**: `core.smart_extractor.SmartExtractor`\n- **Status**: Compliant\n- **Evidence**:\n    - **Invariant 1 (Must operate on raw file content or AST):** The class directly operates on both. The `_enrich_from_source` method reads raw file content using `file_path.read_text(...)` to get the `code_excerpt`. Subsequently, the `_enrich_from_ast` and `_extract_imports` methods use `ast.parse(source)` to generate and traverse a Python Abstract Syntax Tree (AST) to extract structural details like decorators, base classes, and import statements.\n    - **Invariant 2 (Must not perform complex semantic reasoning):** The class focuses on gathering factual, structural, and syntactic context. It extracts code text, docstrings, signatures, and file paths. The `_infer_layer` method uses a simple, non-semantic, path-based pattern matching heuristic. Its primary role is to create a `ComponentCard` as a rich \"context packet\" for a downstream classifier, explicitly avoiding the interpretation of the collected data.\n- **Deviation**: None.\n\n- **Entity**: `core.edge_extractor.EdgeExtractionStrategy` (and implementations)\n- **Status**: Compliant\n- **Evidence**:\n    - **Invariant 1 (Must operate on raw file content or AST):** The system uses a strategy pattern with two types of implementations, both of which comply. Low-precision strategies (e.g., `PythonEdgeStrategy`) use regular expressions (`re.findall`) on raw source code strings (`body_source`). High-precision strategies (e.g., `PythonTreeSitterStrategy`, `JavaScriptTreeSitterStrategy`) use `tree-sitter` to parse the source code into an AST and then traverse it to find call expressions.\n    - **Invariant 2 (Must not perform complex semantic reasoning):** The purpose of these strategies is to extract a call graph, which is a form of structural data ingestion. The logic identifies syntactic constructs that represent calls, inheritance, or usage. Even the most complex component, `JSModuleResolver`, performs name resolution based on syntactic import/export rules. This is a sophisticated form of structural analysis to link identifiers to their definitions, but it does not interpret the *purpose* or *behavior* of the code, which is the role of the Classifier.\n- **Deviation**: None.",
        "guardrails": {
          "status": "ERROR",
          "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'Resource exhausted. Please try again later. Please refer to https://cloud.google.com/vertex-ai/generative-ai/docs/error-code-429 for more details.', 'status': 'RESOURCE_EXHAUSTED'}}"
        }
      }
    }
  ]
}