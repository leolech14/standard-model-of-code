{
  "timestamp": "20260121_100430",
  "domain": "pipeline",
  "execution_id": "pipeline-20260121_100430",
  "generation": 1,
  "parent_execution_id": null,
  "analysis_type": "primary",
  "source": {
    "type": "repository",
    "location": "/Users/lech/PROJECTS_all/PROJECT_elements"
  },
  "results": [
    {
      "hypothesis": {
        "concept": "Stage",
        "claim": "Hypothesis: The concept 'Stage' is implemented according to strict invariants.",
        "description": "A processing unit in the analysis pipeline.",
        "invariants": [
          "Must inherit from a base Stage class (e.g., BaseStage)",
          "Must implement an 'execute' or 'run' method",
          "Should be stateless (no instance variables modified during run)",
          "Must return a standard result format (ProcessingResult/AnalysisResult)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_stage.py",
            "pattern": "class *Stage"
          },
          {
            "file": "standard-model-of-code/src/core/full_analysis.py",
            "pattern": "class FullAnalysisPipeline"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/full_analysis.py"
        ],
        "analysis": "### Findings\n- **Entity**: Analysis Pipeline Functions (`analyze`, `enrich_with_standard_model`, `detect_purpose_field`, `detect_execution_flow`, `compute_markov_matrix`, `detect_knots`, `compute_data_flow`, `predict_performance`, etc.)\n- **Status**: Non-Compliant\n- **Evidence**: The file `/src/core/full_analysis.py` defines a main function `run_full_analysis` that orchestrates a series of processing steps. These steps (e.g., `detect_purpose_field`, `compute_markov_matrix`) are conceptually \"Stages\" as they are distinct processing units in the analysis pipeline. However, their implementation systematically deviates from the specified invariants.\n- **Deviation**: The implementation uses a functional approach rather than the object-oriented structure required by the semantic definition.\n    - **Inheritance**: The stages are implemented as standalone functions, not classes. They do not inherit from a `BaseStage` class.\n    - **Method Name**: Being functions, they do not have an `execute` or `run` method. The function name itself serves as the invocation point (e.g., `knots = detect_knots(nodes, edges)`).\n    - **Statelessness**: The pattern is not stateless. Several stages mutate their input arguments directly. For example, the \"Graph Analytics\" block at Stage 6.5 modifies the `nodes` list in-place by adding keys like `'in_degree'`, `'out_degree'`, and `'topology_role'` to the dictionaries within the list. Similarly, `compute_markov_matrix` modifies the `edges` list in-place: `edge['markov_weight'] = ...`. This violates the principle of statelessness.\n    - **Return Format**: The return format is inconsistent across stages. Some functions return custom objects with methods (e.g., `detect_purpose_field` returns an object with a `.summary()` method), while others return a simple `dict` (e.g., `detect_knots`). None of the return types are named `ProcessingResult` or `AnalysisResult`, failing to adhere to a standard result format.",
        "guardrails": {
          "compliant": false,
          "violations": [
            {
              "law_id": "AM002",
              "severity": "HIGH",
              "reasoning": "The module manipulates `sys.path` directly (`sys.path.insert(0, ...)`), which is a severe architectural anti-pattern. This practice breaks packaging principles, makes module resolution unpredictable, and creates a fragile, environment-dependent system. Furthermore, the `_generate_ai_insights` function uses `subprocess.run` to execute another internal Python script. This creates a brittle, implicit dependency on the filesystem layout and process execution, rather than a clean, explicit dependency via a direct function import, indicating a breakdown in modular design."
            },
            {
              "law_id": "AM004",
              "severity": "MEDIUM",
              "reasoning": "The function `classify_disconnection` is defined at the top of the module but is never called within the file's primary execution flow (`run_full_analysis`). The logic it contains appears to be functionally replaced by the imported `TopologyClassifier` class, which is used later in the pipeline. This makes the large `classify_disconnection` function highly likely to be dead code left over from a refactoring, adding clutter and potential confusion."
            },
            {
              "law_id": "AM001",
              "severity": "LOW",
              "reasoning": "The utility functions `_open_file` and `_manual_open_command` implement OS-specific logic for opening files. While self-contained, this is common functionality that could be centralized in a shared project utility module to avoid potential duplication across different command-line entry points."
            }
          ],
          "critique_summary": "The orchestration script is non-compliant due to significant architectural drift via import path manipulation and shelling out to internal tools, and it also contains a large block of likely dead code."
        }
      }
    },
    {
      "hypothesis": {
        "concept": "Extractor",
        "claim": "Hypothesis: The concept 'Extractor' is implemented according to strict invariants.",
        "description": "Component responsible for raw data ingestion.",
        "invariants": [
          "Must operate on raw file content or AST",
          "Must not perform complex semantic reasoning (role of Classifier)"
        ],
        "anchors": [
          {
            "file": "standard-model-of-code/src/core/*_extractor*.py",
            "pattern": "class *Extractor"
          }
        ],
        "scope": "standard-model-of-code/src/core/**"
      },
      "result": {
        "verified": true,
        "candidates": [
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/smart_extractor.py",
          "/Users/lech/PROJECTS_all/PROJECT_elements/standard-model-of-code/src/core/edge_extractor.py"
        ],
        "analysis": "### Findings\n- **Entity**: `SmartExtractor`\n- **Status**: Compliant\n- **Evidence**: The class `SmartExtractor` is responsible for extracting a `ComponentCard` for code elements. It directly fulfills the invariants:\n    1.  **Operates on raw file content or AST**: The `_enrich_from_source` method reads the raw file using `file_path.read_text(...)`. The `_enrich_from_ast` method then parses this content into an Abstract Syntax Tree using `ast.parse(source)` to extract structural details like decorators, base classes, and docstrings.\n    2.  **Does not perform complex semantic reasoning**: The class gathers factual, structural information (code text, AST nodes, call graph connections). The most complex operation, `_infer_layer`, is a simple heuristic that matches file paths against a predefined list of patterns. This is a form of structural pattern matching on metadata (the file path), not complex reasoning about the code's behavior or purpose. Its primary role is to prepare a rich data packet for a downstream Classifier.\n- **Deviation**: None.\n\n- **Entity**: `EdgeExtractor` (and its `EdgeExtractionStrategy` implementations)\n- **Status**: Compliant\n- **Evidence**: This component is responsible for extracting relationships (edges) between code elements.\n    1.  **Operates on raw file content or AST**: The strategies use one of two methods: regex-based strategies (e.g., `PythonEdgeStrategy`) operate on the raw `body_source` string using `re.findall`. Tree-sitter based strategies (e.g., `PythonTreeSitterStrategy`, `JavaScriptTreeSitterStrategy`) explicitly parse the source code into an AST (`self.parser.parse(source_bytes)`) and query it to find calls.\n    2.  **Does not perform complex semantic reasoning**: The component's goal is to identify structural connections like function calls or inheritance. While implementations like `JavaScriptTreeSitterStrategy` and its helper `JSModuleResolver` perform non-trivial analysis to resolve module imports and aliases, this is still a form of structural reasoning to accurately identify the target of a call. It answers \"what does this code connect to?\" not \"what is the purpose of this code?\". This task is a sophisticated form of data ingestion, not semantic classification.\n- **Deviation**: None.",
        "guardrails": {
          "compliant": false,
          "violations": [
            {
              "law_id": "AM002",
              "severity": "HIGH",
              "reasoning": "The component's role, as defined by the `EdgeExtractionStrategy` interface, is to extract edges from a code particle. The provided implementation references an undefined variable 'part', which will cause a `NameError` at runtime. This fundamental error renders the method completely non-functional, representing a total failure to perform its designated architectural role. The component has drifted from its intended function (extraction) to an unintended one (crashing)."
            },
            {
              "law_id": "AM001",
              "severity": "MEDIUM",
              "reasoning": "The code exhibits severe context myopia by failing to correctly access its own input data. The method receives a `particle` dictionary as an argument, which presumably contains the source code to be analyzed, but it ignores this and attempts to use a non-existent variable 'part'. This demonstrates a complete disconnect from its immediate operational context and input data contract."
            }
          ],
          "critique_summary": "The code is non-functional and fails its architectural mandate due to a fatal `NameError` from referencing an undefined variable."
        }
      }
    }
  ]
}